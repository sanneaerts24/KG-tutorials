{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Graphs and Semantic Technologies -- KG measures and clustering tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, make sure you have networkx installed, here you can find the [documentation](https://networkx.org/documentation/stable/reference/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "## Uncomment if you do not have networkx installed (you should have it installed from the RDFS tutorial)\n",
    "#import sys\n",
    "#!{sys.executable} -m pip install networkx\n",
    "\n",
    "import pandas as pd\n",
    "import rdflib\n",
    "from rdflib import Literal\n",
    "from rdflib.namespace import DC, FOAF\n",
    "\n",
    "import networkx as nx\n",
    "from owlready2 import *"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will focus on how to characterize an ontology or knowledge graph.\n",
    "\n",
    "Load the ontology, which you have previously created in the OWL tutorial (load the asserted owl file)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "ontology = rdflib.Graph()\n",
    "ontology.parse(\"data/my_music_ontology_inferred.owl\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic (ontology) measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first focus on calculating basic measures:\n",
    "* number of classes\n",
    "* number of properties\n",
    "* number of individuals\n",
    "* number of triples\n",
    "* number of entities (classes, individuals, etc. anything that can be places in the subject possition in a triple/axiom)\n",
    "\n",
    "We start by counting the number of classes in the ontology. This can be done using a SPARQL query. We want to get the unique classes used in the ontology. \n",
    "\n",
    "PREFIX owl: <http://www.w3.org/2002/07/owl#> \n",
    "SELECT DISTINCT ?s \n",
    "WHERE { ?s rdf:type owl:Class. FILTER isURI(?s) }')\n",
    "\n",
    "This query gives as all the classes that also have a definition in the ontology. However, this does not have to equal the number of classes actually used by individuals. Hence, you need to be very specific about what the number you are retriving represents."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "answer = list(ontology.query(\n",
    "    'PREFIX owl: <http://www.w3.org/2002/07/owl#> SELECT DISTINCT ?s WHERE { ?s rdf:type owl:Class. FILTER isURI(?s) }'\n",
    "))\n",
    "print(\"Number of classes: {f}\".format(f=len(answer)))\n",
    "for r in answer:\n",
    "    print(r)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though we used a query, a lot of this information can also be retrieved with owlready2. For example, the number of classes can be retrieved with the function onto.classes(). It returns all classes in the ontology. We try it below."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "onto_file = \"data/my_music_ontology_inferred.owl\"\n",
    "or_ontology = get_ontology(onto_file).load()\n",
    "answer = list(or_ontology.classes())\n",
    "\n",
    "print(\"Number of classes: {f}\".format(f=len(answer)))\n",
    "for r in answer:\n",
    "    print(r)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "ind = list(or_ontology.individuals())\n",
    "print(len(ind))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Get the following metrics from the Hybrid Intelligence ontology, using queries and check your answer using owlready2 functions.\n",
    "WARNING: loading the .ttl file might cause the parsing to break. You can pre-process the file by loading it with rdflib and serializing it into ntriples/nt.\n",
    "\n",
    "* number of properties\n",
    "* number of individuals\n",
    "* number of triples\n",
    "* number of entities (classes, individuals, etc. anything that can be places in the subject possition in a triple/axiom)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "### your code here.",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Converting KGs into Gs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make use of graph measure, we need to convert our ontology into a mathematical graph networkx.\n",
    "\n",
    "\n",
    "We first need to remove all the logics before we can do the conversion.\n",
    "We are interested in keeping the following things:\n",
    "* individual\n",
    "* classes\n",
    "* relationships between individuals and classes\n",
    "\n",
    "What we need to remove is:\n",
    "* restrictions\n",
    "* domain/range\n",
    "* property definitions\n",
    "\n",
    "There is two ways for us to do it: we can either remove the information from the existing graph, or create a new graph using only the information we are interested in. Depending on the size and complexity of your knowledge graph, one way will be more preferrable than the other. You also need to consider if you want to keep the inferred information in your graph after conversion or not. Here, we want to keep the inferred information, but that is depended on the task you will then execute (for link prediction, you probably want the uninferred ontology and use the inferred information as a test set)\n",
    "\n",
    "rdflib comes with a function that lets us convert a rdflib graph into an networkx graph."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from rdflib.extras.external_graph_libs import rdflib_to_networkx_digraph\n",
    "nx_graph = rdflib_to_networkx_digraph(ontology)\n",
    "\n",
    "list(nx_graph.nodes())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there are some blank nodes which were convered into the graph that are not very useful for us at this stage. To analyse the graph as a mathematical graph, we don't want the class restrictions or property range and domain definision in our graph, as we are not doing any reasoning anymore.\n",
    "\n",
    "Often times, it is easier to create a new graph than removeing already modeled information from the graph. Instead of continuing with the ontology, we will create a graph from the metadata provided in 'data/musicoset_metadata', but will adhere to the ontology from before (use the property and class names,etc.)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "csv_albums =  pd.read_csv('data/musicoset_metadata/albums.csv',sep='\\t')\n",
    "print(csv_albums.columns)\n",
    "csv_artists =  pd.read_csv('data/musicoset_metadata/artists.csv',sep='\\t')\n",
    "print(csv_artists.columns)\n",
    "csv_songs =  pd.read_csv('data/musicoset_metadata/songs.csv',sep='\\t')\n",
    "print(csv_songs.columns)\n",
    "csv_tracks =  pd.read_csv('data/musicoset_metadata/tracks.csv',sep='\\t')\n",
    "print(csv_tracks.columns)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# We have prepared a simplified ontology to use in this tutorial\n",
    "# This ontology doesn't have any restrictions or domain/range definitions\n",
    "# this is to avoid blank nodes when converting to networx\n",
    "music_onto = rdflib.Graph()\n",
    "music_onto.parse(\"data/music_onto_simple.rdf\")\n",
    "\n",
    "nx_music = rdflib_to_networkx_digraph(music_onto)\n",
    "list(nx_music.nodes())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ontology no longer produces any blank nodes. So we can now populate it with the metadata loaded from the CSV."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "music_onto.parse(\"data/music_onto_simple.rdf\")\n",
    "\n",
    "EX = rdflib.Namespace(\"http://test.org/myonto.owl#\")\n",
    "from rdflib import OWL,RDF,RDFS,URIRef\n",
    "import json\n",
    "solo_artists = [\"singer\",'rapper','DJ',]\n",
    "band = ['band','duo']\n",
    "undef = ['-']\n",
    "\n",
    "for index, artist in csv_artists.iterrows():\n",
    "    art = URIRef(EX+artist[\"artist_id\"])\n",
    "    if artist[\"artist_type\"] in solo_artists:\n",
    "        music_onto.add((art,RDF.type,EX.SoloArtist))\n",
    "    elif artist[\"artist_type\"] in band:\n",
    "        music_onto.add((art,RDF.type,EX.Band))\n",
    "    else:\n",
    "        music_onto.add((art,RDF.type,EX.Artist))\n",
    "        \n",
    "    music_onto.add((art,EX.name,Literal(artist[\"name\"])))\n",
    "    music_onto.add((art,EX.followers,Literal(artist[\"followers\"])))\n",
    "    genre = URIRef(EX+artist[\"main_genre\"].replace(' ', '_'))\n",
    "    music_onto.add((art,EX.hasGenre,genre))\n",
    "    music_onto.add((genre,RDF.type,EX.Genre))\n",
    "    \n",
    "for index, song in csv_songs.iterrows():\n",
    "    s = URIRef(EX+song[\"song_id\"])\n",
    "    music_onto.add((s,RDF.type,EX.Song))\n",
    "    music_onto.add((s,EX.name,Literal(song['song_name'])))\n",
    "    artists = eval(song['artists'])\n",
    "    for key in artists.keys():\n",
    "        art = URIRef(EX+key)\n",
    "        music_onto.add((art,EX.authorOf,s))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to extend your ontology to include albums and track information below. You might have to extend the basic ontology as well with some additional relations."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "### place your code here"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we convert the ontology to a networkx graph."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "nx_music_graph = rdflib_to_networkx_digraph(music_onto)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "* Convert the Hybrid Intellgence ontology into a networkx graph. \n",
    "* Write a function that checks for blank nodes in your networkx graph, and apply it both to the graph created above (nx_graph) and to the one you have created just now."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "### place your code here"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Graph Measures\n",
    "\n",
    "Now we can calculate some graph measures over the networkX graph. The library provides a lot of different measures that can be calculated. Always check what kind of assumptions the measure has:\n",
    "* directed or undirected graph?\n",
    "* does the graph have to be connected?\n",
    "\n",
    "We will first calculate some basic graph measures: number of nodes, number of edges and the density of the graph."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"Number of Nodes: {n}\".format(n=nx.number_of_nodes(nx_music_graph)))\n",
    "print(\"Number of Edges: {n}\".format(n=nx.number_of_edges(nx_music_graph)))\n",
    "print(\"Density of Graph: {n}\".format(n=nx.density(nx_music_graph)))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now look at the distribution of degree of our nodes by calculating (retrieving) the degree for each node and plotting a histogram. We do this with the original ontology, to show how it works. The graph which we just created is not dense enough to show much in a histogram. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "histdegree = pd.DataFrame(nx.degree_histogram(nx_graph))\n",
    "degree = dict(nx.degree(nx_graph))\n",
    "\n",
    "\n",
    "mean_degree = np.mean(list(degree.values()))\n",
    "mean_degree_centrality = np.mean(list(nx.degree_centrality(nx_graph).values()))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,6)) \n",
    "ax.bar(histdegree.index.values,histdegree[0])\n",
    "\n",
    "plt.title(\"Mean Degree: {n1}\\n Mean Degree Centrality: {n2}\".format(n1=mean_degree,n2=mean_degree_centrality))\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another very useful measure is the clustering coefficient, which tells us how likely the nodes are to build clusters. This is a global measure, but can also be calculated for each node."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"Clustering coefficient: {n}\".format(n=nx.average_clustering(nx_graph)))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Calculate and visualise the centrality of the music graph. Use a different measure than degree. For different measures you can refer to this online [documentation]{https://networkx.org/documentation/stable/reference/algorithms/centrality.html}. Choose wisely though, some measures require a long time to calculate (like betweenness or eigenvector centrality).\n",
    "\n",
    "As a second step, take some time to explore the documentation of networkx. Is there something other you can calculate and learn about the graph?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "### your code here"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualizing your graph\n",
    "\n",
    "With networkX you can easily visualize your ontology/graph, no matter if they include blank nodes or not. The visualisations are powered by matplotlib. We will use here the first ontology, which also has blank nodes, but is much simpler to visualize."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# list(nx_graph.nodes())\n",
    "\n",
    "music_ontology = rdflib.Graph()\n",
    "music_ontology.parse(\"data/music_onto_simple.rdf\")\n",
    "nx_graph = rdflib_to_networkx_digraph(music_ontology)\n",
    "\n",
    "\n",
    "mapping = pd.DataFrame(nx_graph.nodes())\n",
    "mapping['new_names'] = mapping[0].str.split(\"#\",n=1,expand=False)\n",
    "mapping['label'] = 'NA'\n",
    "# print(mapping)\n",
    "mapping_copy = mapping.copy()\n",
    "\n",
    "for ind, m in mapping_copy.iterrows():\n",
    "    l = len(m['new_names'])\n",
    "    names = m['new_names']\n",
    "    mapping.loc[ind,'label'] = names[l-1]\n",
    "    \n",
    "map_dict = dict(zip(mapping[0],mapping['label']))\n",
    "\n",
    "# print(mapping)\n",
    "nx_graph_nl = nx.relabel_nodes(nx_graph,map_dict,copy=True)\n",
    "\n",
    "\n",
    "nx.draw_planar(nx_graph_nl,\n",
    "                 with_labels=True,\n",
    "                node_size=200, font_size=8 )\n",
    "# plt.draw()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "Try to visualize the Hybrid Intelligence ontology below. Don't shy away from looking for and trying other approaches to visualize an ontology, giving nodes different colors, or varying thickness/color of the edges based on the type of relation."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "### your code goes here"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Clustering\n",
    "\n",
    "NetworkX already comes with some clustering algorithms. We will try the one introduced in the theory part of the class, Louvain clustering algorithm."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import networkx.algorithms.community as nx_comm\n",
    "\n",
    "\n",
    "communities = nx_comm.louvain_communities(nx_graph,resolution=1)\n",
    "print(1,len(communities),nx.number_of_nodes(nx_graph))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can visualize the graph and the communities within it. Alternatively you can also visualize a community as an example alone. (WARNING: this might take a while...)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "pos = nx.shell_layout(nx_graph)\n",
    "\n",
    "\n",
    "nx.draw(nx_graph, pos, edge_color='k',font_weight='light', \n",
    "        node_size= 100, width= 0.8)\n",
    "for com in communities:\n",
    "    nx.draw_networkx_nodes(nx_graph,\n",
    "                           pos,\n",
    "                           nodelist=com, \n",
    "                           node_color=np.random.rand(3,),\n",
    "                           node_size=100)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If clustering is successful and helpful is very dependent on your graph. It is beneficial to remove the information from your graph that is not helpful for the clustering, like the T-box of your ontology, as this \"polutes\" the graph. The clustering algorithm is not made for knowledge graphs but rather for mathematical graphs, hence less semantics is better.\n",
    "\n",
    "In the case above, the graph is not dense enough to produce meaningful clusters, which is why there are 38706 clusters. \n",
    "\n",
    "### Exercise 5\n",
    "\n",
    "Try to cluster your own graph. You might have to create a mathematical graph first, rather than just converting your knowledge graph, as that will lead to better and more insightful results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "### your code goes here."
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
